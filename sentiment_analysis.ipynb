{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pjoin = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- awww, that's a bummer.  you shoulda got da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball. managed to s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0    - awww, that's a bummer.  you shoulda got da...          0\n",
       "1  is upset that he can't update his facebook by ...          0\n",
       "2   i dived many times for the ball. managed to s...          0\n",
       "3     my whole body feels itchy and like its on fire          0\n",
       "4   no, it's not behaving at all. i'm mad. why am...          0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read pre-processed data from pickle file\n",
    "pkl_dir = './data/tweet/sentiment_analysis/pkl'\n",
    "processed_df = pd.read_pickle(pjoin(pkl_dir, 'processed_tweets_sentiments.pkl'))\n",
    "\n",
    "# Swap tweet and sentiment columns\n",
    "processed_df = processed_df.reindex(columns=['Tweet', 'Sentiment'])\n",
    "\n",
    "print(processed_df['Sentiment'].unique())\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1279922, (80.0 %)\n",
      "Number of testing samples: 320078 (20.0 %)\n"
     ]
    }
   ],
   "source": [
    "# Divide 1.6M tweets into training (~80%) and testing (~20%) sets!\n",
    "mask = np.random.rand(len(processed_df)) < 0.8\n",
    "training_df = processed_df[mask]\n",
    "test_df = processed_df[~mask]\n",
    "\n",
    "num_train, num_test = len(training_df), len(test_df)\n",
    "percent_train, percent_test = num_train/len(mask), num_test/len(mask)\n",
    "\n",
    "print(f'Number of training samples: {len(training_df)}, ({percent_train*100:.1f} %)')\n",
    "print(f'Number of testing samples: {len(test_df)} ({percent_test*100:.1f} %)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400525it [00:36, 11024.04it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_vocabulary(training_df):\n",
    "    '''\n",
    "    Given the pre-processed training data in a pandas dataframe, \n",
    "    construct the whole vocabulary set resident in the training data.\n",
    "    '''\n",
    "    all_words = []\n",
    "    \n",
    "    for (index, data) in tqdm(training_df.iterrows()):\n",
    "        # data['Tweet'] contains the list of words in that tweet\n",
    "        all_words.extend(data['Tweet'])\n",
    "        \n",
    "        \n",
    "    wordlist = nltk.FreqDist(all_words)\n",
    "    word_features = wordlist.keys()\n",
    "    \n",
    "    return word_features\n",
    "\n",
    "# Get list of words (the whole vocabulary in the set)\n",
    "word_features = build_vocabulary(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet):\n",
    "    '''\n",
    "    For every word in word_features, compare with the words in tweet and create a label:\n",
    "    \n",
    "    Label 1 (true): Word in vocabulary is resident in tweet\n",
    "    Label 0 (false): Word in vocabulary is not resident in tweet\n",
    "    '''\n",
    "    tweet_words = set(tweet)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[f'Contains {word}'] = word in tweet_words\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Transform training dataframe to a list of lists\n",
    "# for compatibility with NLTK built-in function\n",
    "training_list = training_df.iloc[:100].values.tolist()\n",
    "\n",
    "training_features = nltk.classify.apply_features(extract_features, training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 1585894743.1434581\n",
      "End: 1585894767.7725508\n",
      "Time taken: 24.629092693328857\n"
     ]
    }
   ],
   "source": [
    "# Train the Naive Bayes Classifier\n",
    "import time\n",
    "start_time = time.time()\n",
    "print(f'Start: {start_time}')\n",
    "bayes_classifier = nltk.NaiveBayesClassifier.train(training_features)\n",
    "end_time = time.time()\n",
    "print(f'End: {end_time}')\n",
    "diff = end_time - start_time\n",
    "print(f'Time taken: {diff}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1279922, 237696)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tweets = training_df['Tweet'].values.tolist()\n",
    "X_train_sentiments = training_df['Sentiment'].values.tolist()\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train_tweets)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1279922, 237696)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide the occurences with total number of words in each tweet (normalize)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier with normalized frequency distributions\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, X_train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320078, 237696)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7823155605821082"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model\n",
    "X_test_tweets = test_df['Tweet'].values.tolist()\n",
    "X_test_sentiments = test_df['Sentiment'].values.tolist()\n",
    "X_test_counts = count_vect.transform(X_test_tweets)\n",
    "print(X_test_counts.shape)\n",
    "\n",
    "clf.score(X_test_counts, X_test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
